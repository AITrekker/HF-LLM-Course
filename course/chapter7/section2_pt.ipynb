{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token classification (PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required libraries for token classification and model training\n!uv pip install datasets evaluate transformers[sentencepiece]\n!uv pip install accelerate\n# To run the training on TPU, you will need to uncomment the following line:\n# !uv pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n!apt install git-lfs"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to setup git, adapt your email and name in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configure git credentials for model pushing to Hugging Face Hub\n!git config --global user.email \"you@example.com\"\n!git config --global user.name \"Your Name\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to be logged in to the Hugging Face Hub. Execute the following and enter your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Login to Hugging Face Hub for model upload and access to private models\nfrom huggingface_hub import notebook_login\n\nnotebook_login()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load the CoNLL-2003 dataset for Named Entity Recognition (NER)\n# This dataset contains news articles with entities labeled as PER, ORG, LOC, MISC\nfrom datasets import load_dataset\n\nraw_datasets = load_dataset(\"conll2003\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Explore the dataset structure - shows train/validation/test splits and features\nraw_datasets"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Examine the tokens (words) in the first training example\nraw_datasets[\"train\"][0][\"tokens\"]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Look at the corresponding NER tags (numeric labels for each token)\nraw_datasets[\"train\"][0][\"ner_tags\"]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get the NER feature information to understand the label encoding\n# This shows the mapping from numeric tags to entity labels\nner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\nner_feature"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract the label names: O (Outside), B- (Beginning), I- (Inside) for PER/ORG/LOC/MISC\nlabel_names = ner_feature.feature.names\nlabel_names"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize the token-label alignment for better understanding\n# This shows how each word corresponds to its entity label\nwords = raw_datasets[\"train\"][0][\"tokens\"]\nlabels = raw_datasets[\"train\"][0][\"ner_tags\"]\nline1 = \"\"\nline2 = \"\"\nfor word, label in zip(words, labels):\n    full_label = label_names[label]\n    max_length = max(len(word), len(full_label))\n    line1 += word + \" \" * (max_length - len(word) + 1)\n    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n\nprint(line1)\nprint(line2)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load the tokenizer for BERT base model (cased version for better entity recognition)\nfrom transformers import AutoTokenizer\n\nmodel_checkpoint = \"bert-base-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check if we're using a fast tokenizer (needed for word_ids() method)\ntokenizer.is_fast"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Tokenize the first example and see how words are split into subwords\n# is_split_into_words=True tells the tokenizer the input is already word-tokenized\ninputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\ninputs.tokens()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get word IDs to track which subword tokens belong to which original words\n# None values correspond to special tokens [CLS] and [SEP]\ninputs.word_ids()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Function to align NER labels with tokenized input\n# When words are split into subwords, we need to align labels accordingly\ndef align_labels_with_tokens(labels, word_ids):\n    new_labels = []\n    current_word = None\n    for word_id in word_ids:\n        if word_id != current_word:\n            # Start of a new word!\n            current_word = word_id\n            label = -100 if word_id is None else labels[word_id]  # -100 for special tokens\n            new_labels.append(label)\n        elif word_id is None:\n            # Special token\n            new_labels.append(-100)\n        else:\n            # Same word as previous token (subword continuation)\n            label = labels[word_id]\n            # If the label is B-XXX we change it to I-XXX for subword tokens\n            if label % 2 == 1:\n                label += 1\n            new_labels.append(label)\n\n    return new_labels"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test the label alignment function on our first example\nlabels = raw_datasets[\"train\"][0][\"ner_tags\"]\nword_ids = inputs.word_ids()\nprint(labels)\nprint(align_labels_with_tokens(labels, word_ids))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Preprocessing function to tokenize and align labels for the entire dataset\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"], truncation=True, is_split_into_words=True\n    )\n    all_labels = examples[\"ner_tags\"]\n    new_labels = []\n    for i, labels in enumerate(all_labels):\n        word_ids = tokenized_inputs.word_ids(i)\n        new_labels.append(align_labels_with_tokens(labels, word_ids))\n\n    tokenized_inputs[\"labels\"] = new_labels\n    return tokenized_inputs"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Apply tokenization and label alignment to the entire dataset\n# This processes all splits (train, validation, test) and removes original columns\ntokenized_datasets = raw_datasets.map(\n    tokenize_and_align_labels,\n    batched=True,\n    remove_columns=raw_datasets[\"train\"].column_names,\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create a data collator for token classification that handles dynamic padding\n# This ensures all sequences in a batch have the same length\nfrom transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test the data collator by creating a batch from two examples\n# Notice how shorter sequences are padded with -100 for labels\nbatch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\nbatch[\"labels\"]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare original label lengths before padding\nfor i in range(2):\n    print(tokenized_datasets[\"train\"][i][\"labels\"])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install seqeval for proper NER evaluation metrics\n!uv pip install seqeval"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load the seqeval metric which correctly handles entity-level evaluation\n# Unlike token-level accuracy, this evaluates complete entities\nimport evaluate\n\nmetric = evaluate.load(\"seqeval\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Convert numeric labels to string labels for metric evaluation\nlabels = raw_datasets[\"train\"][0][\"ner_tags\"]\nlabels = [label_names[i] for i in labels]\nlabels"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example of metric evaluation: simulate a prediction error (B-MISC â†’ O)\n# This shows entity-level precision, recall, and F1 scores\npredictions = labels.copy()\npredictions[2] = \"O\"  # Change \"B-MISC\" to \"O\" (miss one entity)\nmetric.compute(predictions=[predictions], references=[labels])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define metric computation function for training evaluation\nimport numpy as np\n\n\ndef compute_metrics(eval_preds):\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n\n    # Remove ignored index (special tokens) and convert to labels\n    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": all_metrics[\"overall_precision\"],\n        \"recall\": all_metrics[\"overall_recall\"],\n        \"f1\": all_metrics[\"overall_f1\"],\n        \"accuracy\": all_metrics[\"overall_accuracy\"],\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create label mappings for the model configuration\nid2label = {i: label for i, label in enumerate(label_names)}\nlabel2id = {v: k for k, v in id2label.items()}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load the model for token classification with proper label configuration\n# The model will have 9 output classes (one for each NER label)\nfrom transformers import AutoModelForTokenClassification\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    model_checkpoint,\n    id2label=id2label,\n    label2id=label2id,\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify the model has the correct number of output labels\nmodel.config.num_labels"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Login again to ensure access for model pushing (if needed)\nfrom huggingface_hub import notebook_login\n\nnotebook_login()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configure training arguments for fine-tuning\nfrom transformers import TrainingArguments\n\nargs = TrainingArguments(\n    \"bert-finetuned-ner\",  # Output directory name\n    evaluation_strategy=\"epoch\",  # Evaluate after each epoch\n    save_strategy=\"epoch\",  # Save checkpoint after each epoch\n    learning_rate=2e-5,  # Learning rate optimized for BERT fine-tuning\n    num_train_epochs=3,  # Number of training epochs\n    weight_decay=0.01,  # L2 regularization\n    push_to_hub=True,  # Automatically push model to Hugging Face Hub\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize and run the trainer for fine-tuning BERT on NER\nfrom transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=tokenizer,\n)\ntrainer.train()  # Start training process"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Upload the trained model to Hugging Face Hub\ntrainer.push_to_hub(commit_message=\"Training complete\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Alternative: Manual training loop with PyTorch DataLoaders\n# Create data loaders for training and evaluation\nfrom torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(\n    tokenized_datasets[\"train\"],\n    shuffle=True,  # Shuffle training data\n    collate_fn=data_collator,\n    batch_size=8,\n)\neval_dataloader = DataLoader(\n    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=8\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize a fresh model for manual training loop\nmodel = AutoModelForTokenClassification.from_pretrained(\n    model_checkpoint,\n    id2label=id2label,\n    label2id=label2id,\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Set up optimizer with AdamW (recommended for transformers)\nfrom torch.optim import AdamW\n\noptimizer = AdamW(model.parameters(), lr=2e-5)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Use Accelerate for distributed training and mixed precision\nfrom accelerate import Accelerator\n\naccelerator = Accelerator()\nmodel, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n    model, optimizer, train_dataloader, eval_dataloader\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Set up learning rate scheduler for better convergence\nfrom transformers import get_scheduler\n\nnum_train_epochs = 3\nnum_update_steps_per_epoch = len(train_dataloader)\nnum_training_steps = num_train_epochs * num_update_steps_per_epoch\n\nlr_scheduler = get_scheduler(\n    \"linear\",  # Linear decay schedule\n    optimizer=optimizer,\n    num_warmup_steps=0,  # No warmup steps\n    num_training_steps=num_training_steps,\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Set up repository for model versioning and sharing\nfrom huggingface_hub import Repository, get_full_repo_name\n\nmodel_name = \"bert-finetuned-ner-accelerate\"\nrepo_name = get_full_repo_name(model_name)\nrepo_name"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone the repository for local saving and version control\noutput_dir = \"bert-finetuned-ner-accelerate\"\nrepo = Repository(output_dir, clone_from=repo_name)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Post-processing function to prepare predictions and labels for evaluation\ndef postprocess(predictions, labels):\n    predictions = predictions.detach().cpu().clone().numpy()\n    labels = labels.detach().cpu().clone().numpy()\n\n    # Remove ignored index (special tokens) and convert to labels\n    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    return true_labels, true_predictions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Manual training loop with evaluation and model saving\nfrom tqdm.auto import tqdm\nimport torch\n\nprogress_bar = tqdm(range(num_training_steps))\n\nfor epoch in range(num_train_epochs):\n    # Training phase\n    model.train()\n    for batch in train_dataloader:\n        outputs = model(**batch)\n        loss = outputs.loss\n        accelerator.backward(loss)  # Backward pass with accelerate\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)\n\n    # Evaluation phase\n    model.eval()\n    for batch in eval_dataloader:\n        with torch.no_grad():\n            outputs = model(**batch)\n\n        predictions = outputs.logits.argmax(dim=-1)\n        labels = batch[\"labels\"]\n\n        # Pad predictions and labels for distributed training\n        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n\n        # Gather predictions from all processes\n        predictions_gathered = accelerator.gather(predictions)\n        labels_gathered = accelerator.gather(labels)\n\n        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n        metric.add_batch(predictions=true_predictions, references=true_labels)\n\n    # Compute and print evaluation results\n    results = metric.compute()\n    print(\n        f\"epoch {epoch}:\",\n        {\n            key: results[f\"overall_{key}\"]\n            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n        },\n    )\n\n    # Save model and push to hub after each epoch\n    accelerator.wait_for_everyone()\n    unwrapped_model = accelerator.unwrap_model(model)\n    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n    if accelerator.is_main_process:\n        tokenizer.save_pretrained(output_dir)\n        repo.push_to_hub(\n            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n        )"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Final model save after training completion\naccelerator.wait_for_everyone()\nunwrapped_model = accelerator.unwrap_model(model)\nunwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test the trained model using a pipeline for easy inference\n# aggregation_strategy=\"simple\" groups B- and I- tokens into complete entities\nfrom transformers import pipeline\n\n# Replace this with your own checkpoint\nmodel_checkpoint = \"huggingface-course/bert-finetuned-ner\"\ntoken_classifier = pipeline(\n    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n)\ntoken_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
  }
 ],
 "metadata": {
  "colab": {
   "name": "Token classification (PyTorch)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (HF-notebooks)",
   "language": "python",
   "name": "HF-notebooks"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}