{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required libraries for Transformers, datasets, evaluation, and Gradio interface\n!uv pip install datasets evaluate transformers[sentencepiece]\n!uv pip install gradio"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Introduction to Blocks - more flexible alternative to Interface\n# Blocks allows for custom layouts, multiple functions, and complex interactions\nimport gradio as gr\n\n\ndef flip_text(x):\n    # Simple function to reverse text strings\n    return x[::-1]\n\n\n# Create a Blocks app with custom layout and styling\ndemo = gr.Blocks()\n\nwith demo:\n    # Add markdown content for instructions and formatting\n    gr.Markdown(\n        \"\"\"\n    # Flip Text!\n    Start typing below to see the output.\n    \"\"\"\n    )\n    # Create input and output textboxes\n    input = gr.Textbox(placeholder=\"Flip this text\")\n    output = gr.Textbox()\n\n    # Set up event handling: when input changes, trigger flip_text function\n    # This enables real-time text flipping as user types\n    input.change(fn=flip_text, inputs=input, outputs=output)\n\ndemo.launch()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Advanced Blocks layout with tabs, rows, and multiple functions\n# This demonstrates complex UI organization and multiple processing functions\nimport numpy as np\nimport gradio as gr\n\ndemo = gr.Blocks()\n\n\ndef flip_text(x):\n    # Reverse text character by character\n    return x[::-1]\n\n\ndef flip_image(x):\n    # Flip image horizontally using numpy\n    # np.fliplr flips array left-right (horizontal flip)\n    return np.fliplr(x)\n\n\nwith demo:\n    gr.Markdown(\"Flip text or image files using this demo.\")\n    \n    # Create tabbed interface for different functionalities\n    with gr.Tabs():\n        # First tab: Text flipping functionality\n        with gr.TabItem(\"Flip Text\"):\n            with gr.Row():  # Arrange components horizontally\n                text_input = gr.Textbox()\n                text_output = gr.Textbox()\n            text_button = gr.Button(\"Flip\")  # Manual trigger button\n            \n        # Second tab: Image flipping functionality  \n        with gr.TabItem(\"Flip Image\"):\n            with gr.Row():  # Arrange components horizontally\n                image_input = gr.Image()\n                image_output = gr.Image()\n            image_button = gr.Button(\"Flip\")  # Manual trigger button\n\n    # Set up event handlers for button clicks\n    # Unlike the previous example, these require manual button clicks\n    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n\ndemo.launch()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Text completion interface using external API integration\n# This demonstrates how to integrate external models/APIs into Gradio Blocks\nimport gradio as gr\n\n# Load external GPT-J model API through Gradio's Interface.load()\n# This provides access to large language models without local hosting\napi = gr.Interface.load(\"huggingface/EleutherAI/gpt-j-6B\")\n\n\ndef complete_with_gpt(text):\n    # Use only the last 50 characters as context for efficiency\n    # This prevents overwhelming the API with very long texts\n    # Concatenate original text (minus last 50 chars) with API completion\n    return text[:-50] + api(text[-50:])\n\n\n# Create Blocks interface for text completion\nwith gr.Blocks() as demo:\n    textbox = gr.Textbox(placeholder=\"Type here and press enter...\", lines=4)\n    btn = gr.Button(\"Generate\")\n\n    # Connect button click to completion function\n    # When clicked, processes textbox content and updates same textbox with result\n    btn.click(complete_with_gpt, textbox, textbox)\n\ndemo.launch()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Multi-step pipeline: Speech recognition → Sentiment analysis\n# This demonstrates chaining multiple AI models in a sequential workflow\nfrom transformers import pipeline\nimport gradio as gr\n\n# Load two different AI pipelines for a multi-step process\nasr = pipeline(\"automatic-speech-recognition\", \"facebook/wav2vec2-base-960h\")  # Speech-to-text\nclassifier = pipeline(\"text-classification\")  # Sentiment analysis (default model)\n\n\ndef speech_to_text(speech):\n    # Convert audio file to text using automatic speech recognition\n    # Returns the transcribed text from the audio input\n    text = asr(speech)[\"text\"]\n    return text\n\n\ndef text_to_sentiment(text):\n    # Analyze sentiment of text input\n    # Returns the predicted sentiment label (POSITIVE/NEGATIVE)\n    return classifier(text)[0][\"label\"]\n\n\n# Create multi-step interface using Blocks\ndemo = gr.Blocks()\n\nwith demo:\n    # Create components for the pipeline\n    audio_file = gr.Audio(type=\"filepath\")  # Audio input (file path for model)\n    text = gr.Textbox()                     # Intermediate text output\n    label = gr.Label()                      # Final sentiment output\n\n    # Create buttons for each step of the pipeline\n    b1 = gr.Button(\"Recognize Speech\")      # Step 1: Audio → Text\n    b2 = gr.Button(\"Classify Sentiment\")   # Step 2: Text → Sentiment\n\n    # Connect each button to its respective function\n    # This creates a manual two-step process that users control\n    b1.click(speech_to_text, inputs=audio_file, outputs=text)\n    b2.click(text_to_sentiment, inputs=text, outputs=label)\n\ndemo.launch()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Dynamic interface updates - demonstrates reactive UI components\n# This shows how interface elements can change based on user selections\nimport gradio as gr\n\n\ndef change_textbox(choice):\n    # Function to modify textbox properties based on radio button selection\n    # gr.Textbox.update() allows dynamic modification of component properties\n    if choice == \"short\":\n        return gr.Textbox.update(lines=2, visible=True)      # Small textbox\n    elif choice == \"long\":\n        return gr.Textbox.update(lines=8, visible=True)      # Large textbox  \n    else:\n        return gr.Textbox.update(visible=False)              # Hidden textbox\n\n\n# Create dynamic interface with reactive components\nwith gr.Blocks() as block:\n    # Radio button for selecting essay type\n    radio = gr.Radio(\n        [\"short\", \"long\", \"none\"], \n        label=\"What kind of essay would you like to write?\"\n    )\n    # Textbox that will change based on radio selection\n    text = gr.Textbox(lines=2, interactive=True)\n\n    # Set up reactive behavior: when radio changes, update textbox\n    # This creates a dynamic user experience where UI adapts to selections\n    radio.change(fn=change_textbox, inputs=radio, outputs=text)\n    block.launch()"
  }
 ],
 "metadata": {
  "colab": {
   "name": "Introduction to Blocks",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (HF-notebooks)",
   "language": "python",
   "name": "HF-notebooks"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}