{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrations with the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required libraries for Transformers, datasets, evaluation, and Gradio interface\n!uv pip install datasets evaluate transformers[sentencepiece]\n!uv pip install gradio"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Loading models directly from Hugging Face Hub\n# This demonstrates how to integrate existing models without downloading/hosting them locally\nimport gradio as gr\n\n# Interface metadata for professional presentation\ntitle = \"GPT-J-6B\"\ndescription = \"Gradio Demo for GPT-J 6B, a transformer model trained using Ben Wang's Mesh Transformer JAX. 'GPT-J' refers to the class of model, while '6B' represents the number of trainable parameters. To use it, simply add your text, or click one of the examples to load them. Read more at the links below.\"\narticle = \"<p style='text-align: center'><a href='https://github.com/kingoflolz/mesh-transformer-jax' target='_blank'>GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model</a></p>\"\n\n# Predefined examples help users understand what the model can do\nexamples = [\n    [\"The tower is 324 metres (1,063 ft) tall,\"],\n    [\"The Moon's orbit around Earth has\"],\n    [\"The smooth Borealis basin in the Northern Hemisphere covers 40%\"],\n]\n\n# gr.Interface.load() directly loads models from Hugging Face Hub\n# This eliminates the need to download large models locally\ngr.Interface.load(\n    \"huggingface/EleutherAI/gpt-j-6B\",  # Model identifier on Hugging Face Hub\n    inputs=gr.Textbox(lines=5, label=\"Input Text\"),  # Multi-line text input\n    title=title,\n    description=description,\n    article=article,\n    examples=examples,\n    enable_queue=True,  # Enable queuing for large models to handle multiple users\n).launch()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Loading interfaces from Hugging Face Spaces\n# This loads an entire pre-built interface from a public Space\n# Spaces are hosted Gradio/Streamlit apps on Hugging Face\ngr.Interface.load(\"spaces/abidlabs/remove-bg\").launch()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Customizing loaded interfaces with different inputs and branding\n# This shows how to modify an existing Space interface for your specific use case\ngr.Interface.load(\n    \"spaces/abidlabs/remove-bg\",  # Load the background removal Space\n    inputs=\"webcam\",              # Change input from file upload to webcam\n    title=\"Remove your webcam background!\"  # Add custom title\n).launch()"
  }
 ],
 "metadata": {
  "colab": {
   "name": "Integrations with the Hugging Face Hub",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (HF-notebooks)",
   "language": "python",
   "name": "HF-notebooks"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}