{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if my dataset isn't on the Hub?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Install the Transformers, Datasets, and Evaluate libraries to run this notebook.\n\nThis notebook demonstrates how to work with datasets that aren't available on the Hugging Face Hub, including loading local files and remote datasets."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages for working with datasets\n# - datasets: Core library for loading and processing datasets\n# - evaluate: Library for evaluation metrics\n# - transformers[sentencepiece]: Transformers library with SentencePiece tokenizer support\n!uv pip install datasets evaluate transformers[sentencepiece]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download sample dataset files for demonstration\n# Using wget to download Italian SQuAD dataset files from GitHub\n# These are compressed JSON files containing question-answering data\n!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz\n!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract the compressed JSON files\n# -d: decompress, -k: keep original files, -v: verbose output\n!gzip -dkv SQuAD_it-*.json.gz"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load a local JSON dataset using the Datasets library\n# Key parameters:\n# - \"json\": specifies the dataset format/loader to use\n# - data_files: path to the local JSON file\n# - field=\"data\": specifies which field in the JSON contains the actual data\nfrom datasets import load_dataset\n\nsquad_it_dataset = load_dataset(\"json\", data_files=\"SQuAD_it-train.json\", field=\"data\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display basic information about the loaded dataset\n# Shows the structure, features, and number of rows\nsquad_it_dataset"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Examine the first example in the dataset\n# This shows the nested structure typical of SQuAD-format datasets:\n# - title: article title\n# - paragraphs: list containing context and question-answer pairs\nsquad_it_dataset[\"train\"][0]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load multiple files to create train/test splits\n# Using a dictionary to map split names to file paths\n# This creates a DatasetDict with both training and test sets\ndata_files = {\"train\": \"SQuAD_it-train.json\", \"test\": \"SQuAD_it-test.json\"}\nsquad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")\nsquad_it_dataset"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load compressed files directly without manual extraction\n# The datasets library can handle compressed files automatically\n# This saves disk space and download time\ndata_files = {\"train\": \"SQuAD_it-train.json.gz\", \"test\": \"SQuAD_it-test.json.gz\"}\nsquad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load datasets directly from remote URLs\n# This allows loading datasets without downloading them first\n# Particularly useful for large datasets or when working in cloud environments\nurl = \"https://github.com/crux82/squad-it/raw/master/\"\ndata_files = {\n    \"train\": url + \"SQuAD_it-train.json.gz\",\n    \"test\": url + \"SQuAD_it-test.json.gz\",\n}\nsquad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")"
  }
 ],
 "metadata": {
  "colab": {
   "name": "What if my dataset isn't on the Hub?",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (HF-notebooks)",
   "language": "python",
   "name": "HF-notebooks"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}