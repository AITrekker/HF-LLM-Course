{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharing pretrained models (PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required libraries for Transformers, datasets, and evaluation\n# Also install git-lfs for handling large files in Git repositories\n!uv pip install datasets evaluate transformers[sentencepiece]\n!apt install git-lfs"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to setup git, adapt your email and name in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global user.email \"you@example.com\"\n",
    "!git config --global user.name \"Your Name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to be logged in to the Hugging Face Hub. Execute the following and enter your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Login to Hugging Face Hub to access private models and upload your own\n# This will prompt for your Hugging Face token for authentication\nfrom huggingface_hub import notebook_login\n\nnotebook_login()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setting up training arguments with Hub integration\n# push_to_hub=True automatically uploads your model to the Hub after training\n# save_strategy=\"epoch\" saves the model at the end of each training epoch\nfrom transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    \"bert-finetuned-mrpc\", save_strategy=\"epoch\", push_to_hub=True\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Loading a pretrained model and tokenizer for demonstration\n# CamemBERT is a French language model based on RoBERTa architecture\nfrom transformers import AutoModelForMaskedLM, AutoTokenizer\n\ncheckpoint = \"camembert-base\"\n\nmodel = AutoModelForMaskedLM.from_pretrained(checkpoint)\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Uploading a model to the Hub - simplest method\n# This creates a repository under your username with the model files\nmodel.push_to_hub(\"dummy-model\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Uploading the tokenizer to the same repository\n# The tokenizer needs to be uploaded separately to ensure compatibility\ntokenizer.push_to_hub(\"dummy-model\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Uploading to an organization repository\n# Specify the organization parameter to upload under an organization instead of your personal account\ntokenizer.push_to_hub(\"dummy-model\", organization=\"huggingface\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Using explicit authentication token (alternative to notebook_login)\n# You can pass your token directly instead of using the login methods\ntokenizer.push_to_hub(\"dummy-model\", organization=\"huggingface\", use_auth_token=\"<TOKEN>\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Advanced Hub operations using huggingface_hub library\n# These functions provide fine-grained control over Hub operations\nfrom huggingface_hub import (\n    # User management\n    login,\n    logout,\n    whoami,\n\n    # Repository creation and management\n    create_repo,\n    delete_repo,\n    update_repo_visibility,\n\n    # And some methods to retrieve/change information about the content\n    list_models,\n    list_datasets,\n    list_metrics,\n    list_repo_files,\n    upload_file,\n    delete_file,\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Creating a repository manually on the Hub\n# This creates an empty repository that you can then populate with files\nfrom huggingface_hub import create_repo\n\ncreate_repo(\"dummy-model\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Creating a repository under an organization\n# This creates the repo under the specified organization's namespace\nfrom huggingface_hub import create_repo\n\ncreate_repo(\"dummy-model\", organization=\"huggingface\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Uploading individual files to the Hub\n# Use this method when you want to upload specific files one by one\nfrom huggingface_hub import upload_file\n\nupload_file(\n    \"<path_to_file>/config.json\",\n    path_in_repo=\"config.json\",  # Where the file will be stored in the repo\n    repo_id=\"<namespace>/dummy-model\",  # Repository identifier\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Using Git-based workflow with Repository class\n# This clones the repository locally and provides Git operations\nfrom huggingface_hub import Repository\n\nrepo = Repository(\"<path_to_dummy_folder>\", clone_from=\"<namespace>/dummy-model\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Git operations through the Repository object\n# These mirror standard Git commands for version control\nrepo.git_pull()      # Pull latest changes from remote\nrepo.git_add()       # Stage all changes for commit\nrepo.git_commit()    # Commit staged changes\nrepo.git_push()      # Push commits to remote repository\nrepo.git_tag()       # Create a Git tag"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Pull the latest changes from the remote repository\n# Always good practice before making local changes\nrepo.git_pull()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save model and tokenizer files locally to the repository folder\n# This creates all the necessary files for sharing your model\nmodel.save_pretrained(\"<path_to_dummy_folder>\")\ntokenizer.save_pretrained(\"<path_to_dummy_folder>\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Commit and push the model files to the Hub\n# git_add() stages all new files, git_commit() creates a commit, git_push() uploads to Hub\nrepo.git_add()\nrepo.git_commit(\"Add model and tokenizer files\")\nrepo.git_push()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Complete workflow example: load, modify, and save a model\n# This demonstrates the typical pattern for fine-tuning and sharing models\nfrom transformers import AutoModelForMaskedLM, AutoTokenizer\n\ncheckpoint = \"camembert-base\"\n\nmodel = AutoModelForMaskedLM.from_pretrained(checkpoint)\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n# Do whatever with the model, train it, fine-tune it...\n# (Your training/fine-tuning code would go here)\n\n# Save the modified model and tokenizer locally\nmodel.save_pretrained(\"<path_to_dummy_folder>\")\ntokenizer.save_pretrained(\"<path_to_dummy_folder>\")"
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sharing pretrained models (PyTorch)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (HF-notebooks)",
   "language": "python",
   "name": "HF-notebooks"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}